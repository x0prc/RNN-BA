{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Facial Expression Recognition Using LSTM RNN"
      ],
      "metadata": {
        "id": "K-U5eP0cWH4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "baaGOZcuWL9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense"
      ],
      "metadata": {
        "id": "Pf9K25ClW38Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Data and Functions"
      ],
      "metadata": {
        "id": "YijWtyYLXCJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "  return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "  return normalized_image\n",
        "\n",
        "def preserve_edges(image):\n",
        "  return cv2.equalizeHist(image)\n",
        "  return edge_preserved_image"
      ],
      "metadata": {
        "id": "X5PTm88WXCjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define CNN Architecture"
      ],
      "metadata": {
        "id": "TT2kux0OXlOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model(input_shape):\n",
        "  model = tf.keras.Sequential([\n",
        "      Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape),\n",
        "      MaxPooling2D(pool_size=(2, 2)),\n",
        "      Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "      MaxPooling2D(pool_size=(2, 2)),\n",
        "      Flatten()\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "mQasDcIwXoTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Facial Expression Dataset"
      ],
      "metadata": {
        "id": "3ykuZ3tLYUDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"https://www.kaggle.com/datasets/davilsena/ckdataset/data?select=ckextended.csv\"\n",
        "train_data, val_data, test_data = load_dataset(data_path, emotions=[\"happy\", \"sad\", \"angry\"])"
      ],
      "metadata": {
        "id": "HGDOYeYcYVaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Process Data"
      ],
      "metadata": {
        "id": "J0Zh7Py3ZLMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = train_data\n",
        "train_images = np.array([normalize_image(img) for img in train_images])\n",
        "train_images = np.array([preserve_edges(img) for img in train_images])\n",
        "\n",
        "val_images, val_labels = val_data\n",
        "val_images = np.array([normalize_image(img) for img in val_images])\n",
        "val_images = np.array([preserve_edges(img) for img in val_images])\n",
        "\n",
        "test_images, test_labels = test_data\n",
        "test_images = np.array([normalize_image(img) for img in test_images])\n",
        "test_images = np.array([preserve_edges(img) for img in test_images])"
      ],
      "metadata": {
        "id": "ZET_9L3wZMTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defind the Train the Model"
      ],
      "metadata": {
        "id": "BlXLPgxxZYaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  cnn_model(train_images.shape[1:]),\n",
        "  cnn_model(train_images.shape[1:]),\n",
        "  LSTM(128, return_sequences=True),\n",
        "  LSTM(64),\n",
        "  Dense(len(emotions), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "5rlal17zZZBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction on New Images"
      ],
      "metadata": {
        "id": "TR6YdJXYZnIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_image =  normalize_image(new_image)\n",
        "new_image =  preserve_edges(new_image)\n",
        "\n",
        "prediction = model.predict(np.expand_dims(new_image, axis=0))[0]\n",
        "predicted_emotion = emotions[np.argmax(prediction)]\n",
        "print(\"Predicted emotion:\", predicted_emotion)"
      ],
      "metadata": {
        "id": "C6YpM0UdZpAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}