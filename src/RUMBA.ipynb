{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RUMBA-Mouse\n",
        "## Rapid User Mouse-Behavior Authentication Using a CNN-RNN Approach"
      ],
      "metadata": {
        "id": "cCu0W3UcneA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "RZ-r6Nhon0lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "XYha_QfinzUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Mouse Movement Data"
      ],
      "metadata": {
        "id": "J79N1EPln7ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data, window_size):\n",
        "  normalized_data = (data[:, 2:] - data[:, 2:].min(axis=0)) / (data[:, 2:].max(axis=0) - data[:, 2:].min(axis=0))\n",
        "  xy_data = normalized_data[:, 2:]\n",
        "\n",
        "  windowed_data = []\n",
        "  for i in range(len(data) - window_size + 1):\n",
        "    windowed_data.append(xy_data[i:i+window_size])\n",
        "\n",
        "  return np.array(windowed_data)"
      ],
      "metadata": {
        "id": "T36Pj89Xn9rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN + RNN Model"
      ],
      "metadata": {
        "id": "YsMMZ_g9oBtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(window_size, num_users):\n",
        "  # Define CNN model\n",
        "  cnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(window_size, 2)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2)\n",
        "  ])\n",
        "\n",
        "  # Define RNN model\n",
        "  rnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(32)\n",
        "  ])\n",
        "\n",
        "  combined_model = tf.keras.Sequential([\n",
        "    cnn_model,\n",
        "    rnn_model,\n",
        "    tf.keras.layers.Dense(num_users, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  combined_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return combined_model"
      ],
      "metadata": {
        "id": "Q4N58XHZoDnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Window Size and Number of Users"
      ],
      "metadata": {
        "id": "K69bGkLTo4KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 100\n",
        "num_users = 10"
      ],
      "metadata": {
        "id": "lm0VpOx9nkNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data"
      ],
      "metadata": {
        "id": "FXNDfvgmoza7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = preprocess_data(data, window_size)"
      ],
      "metadata": {
        "id": "ppebeP1YowiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "YaOyQcmCo-gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(window_size, num_users)\n",
        "\n",
        "model.fit(preprocessed_data, labels, epochs=10)\n",
        "\n",
        "windowed_data = []\n",
        "for i in range(len(data) - window_size + 1):\n",
        "    windowed_data.append(xy_data[i:i+window_size])\n",
        "\n",
        "prediction = model.predict(windowed_data)"
      ],
      "metadata": {
        "id": "n9uNLNOmpAAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}